# Neural Extraction Framework @DBpedia - GSoC 2025

|   Project Details     |                                                                                                                                                                                               |
|-------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| GSoC Project | [Neural Extraction Framework GSoC'25 @DBpedia](https://summerofcode.withgoogle.com/myprojects/details/uQUHx6jo)                                                                           |
| Contributor | [Gandharva Naveen](https://www.linkedin.com/in/gandharva-naveen)                                                                                                                        |
| Mentors | [Tommaso Soru](), [Abdulsobur Oyewale](), [Diego Moussallem](), [Ronit Banerjee]() |
| Blogs | [GSoC-2025 Gandharva Naveen](https://github.com/Gnav3852/neural-extraction-framework/wiki/)                                                                                                                                   |

### What is Neural Extraction Framework?

The Neural Extraction Framework (NEF) is a system designed to extract structured relational knowledge‚Äîcalled RDF triples‚Äîdirectly from unstructured text. While traditional approaches like [DBpedia](https://www.dbpedia.org/) rely on Wikipedia infoboxes to build knowledge graphs, NEF focuses on uncovering the hidden relationships embedded in natural language. It uses large language models (LLMs), embedding-based retrieval, and ontology alignment to identify entities, match predicates to a known ontology (like DBpedia), and produce machine-readable [relational triples](https://en.wikipedia.org/wiki/Semantic_triple) such as (Albert Einstein ‚Äî award ‚Äî Nobel Prize in Physics).

The goal of NEF is to move beyond static, infobox-based extraction toward a dynamic, intelligent pipeline that continuously learns and adapts. By integrating embedding search, Redis grounding, and LLM reasoning, NEF can both expand existing knowledge graphs and validate extracted information through similarity scoring and ontology mapping. In essence, NEF bridges text and knowledge representation‚Äîtransforming open text into structured, queryable data that allows machines to ‚Äúunderstand the world, one triple at a time.‚Äù


### Code structure
All directories/files have detailed instruction about how to use them in the git wiki posts.
```
üì¶GSoC25/NEF
 ‚î£ üìÇground_truth
 ‚î£ üìÇtest
 ‚î£ üìÇBench.py
 ‚î£ üìÇEmbeddings.py
 ‚î£ üìÇWebscrape.py
 ‚î£ üìÇNEF.py
```

### Installations 
Run the command below to install all requirements of the project at once(preferably in a virtual environment). And set you Gemini API Key under GEMINI_API_KEY in .env.
```
!pip install -r requirements.txt
```

### Run from command line

You need to precompute the DBpedia embeddings before running the NEF.
```
!python NEF/Emeddings.py
```
Then you can run the pipeline like this:
```
!python NEF/NEF.py "Albert Einstein was born in Ulm." --json
```


### Project Workflow

<img width="770" height="980" alt="NEF Workflow (1)" src="https://github.com/user-attachments/assets/d959fb05-5258-426c-a912-1a8534200e9e" />


### Future scope

This project introduced a neural framework for entity‚Äìrelation extraction that combines LLM-based triple generation, Redis-backed entity linking, and embedding-based predicate retrieval. The Enhanced NEF pipeline improves grounding accuracy and contextual understanding over earlier end-to-end methods by enforcing strict validation, predicate thresholding, and disambiguation through Gemini models.

Future work will focus on expanding semantic coverage and adaptability. Planned directions include integrating FAISS-based entity retrieval for broader coverage, refining predicate clustering and ontology alignment to improve generalization, and enabling incremental updates to keep Redis and embedding stores synchronized with evolving knowledge sources.